<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>评分卡校准</title>
      <link href="/2022/06/13/ping-fen-qia-xiao-zhun/"/>
      <url>/2022/06/13/ping-fen-qia-xiao-zhun/</url>
      
        <content type="html"><![CDATA[<h1 id="评分卡校准">评分卡校准</h1><blockquote><p>该文章来自于：<ahref="https://mp.weixin.qq.com/s?__biz=MzUxNjk3MjAzMQ==&amp;mid=2247483814&amp;idx=1&amp;sn=db780349cf113824b85a0afbbc7153fa&amp;chksm=f99e0d36cee984202be7c296391cf92bcd92ec95c044479f5b7e4b2a3d9ec83c36dee30a249e&amp;token=806000883&amp;lang=zh_CN#rd">评分卡校准</a></p></blockquote><h2 id="前言">1. 前言</h2><ol type="1"><li>评分卡校准分为两个场景：1）模型预测概率校准2）样本分数区间坏样本率校准</li><li>评分卡校准原因：由于在建模过程中，出于使坏用户特征表现的更加明显或者坏用户样本量不够等原因，会考虑对好用户进行欠抽样或将表现期不足的样本中的坏用户纳入建模范畴等操作，使得建模样本的坏用户浓度高于产品实际坏用户浓度，两者浓度的不一致导致预测出来的概率值和实际有偏差。</li></ol><h2 id="模型预测概率校准">2. 模型预测概率校准</h2><p>由于建模样本违约率于总体样本违约率存在差异，故使用模型时需要将模型结果进行调整。<br />违约概率（PD）和几率（Odds）的对应关系是： <spanclass="math display">\[ln\left(Odds\right)=ln\frac{PD}{1-PD}\]</span><span class="math display">\[PD=\\frac{e^{ln\left(Odds\right)}}{1+e^{ln\left(Odds\right)}}\]</span>校准基于几率进行，如下式： <spanclass="math display">\[ln\left({Odds}_{adjust}\right)=ln\left(Odds\right)+adjust\]</span>其中，<spanclass="math inline">\(adjust=ln\left({Odds}_{all}\right)-ln\left({Odds}_{sample}\right)，{Odds}_{all}\)</span>为总体样本几率，<spanclass="math inline">\({Odds}_{sample}\)</span>为建模样本几率，则： <spanclass="math display">\[{PD}_{adjust}=\\frac{e^{ln\left({Odds}_{adjust}\right)}}{1+e^{ln\left({Odds}_{adjust}\right)}}\]</span></p><p>特别的，在logistic回归模型下，其预测模型为： <spanclass="math display">\[ln\left(Odds\right)=ln\frac{PD}{1-PD}=\ \alpha+\{\beta}{X}\]</span> 基于几率的校准即体现为对常数项<spanclass="math inline">\(\alpha\)</span>的调整，也即：$$ln\left({Odds}_{adjust}\right)=ln\frac{{PD}_{adjust}}{1-{PD}_{adjust}}={\ \alpha}_{adjust}+\ {\beta}{X}$$ 其中，<span class="math display">\[{\ \alpha}_{adjust}=\\alpha+adjust\]</span></p><p>违约概率（PD）或几率（Odds）都是专业术语，为了方便使用和沟通，需要将违约概率转换为分数，转换原则是将对数几率（ln(Odds)）转换为得分。评分卡尺度变换公式如下：<spanclass="math display">\[Score=A-B\ast\ln{\left({Odds}_{adjust}\right)}=\A-B\ast\left({\ \alpha}_{adjust}+\ {\beta}{X}\right)\]</span></p><h2 id="样本分数区间坏样本率校准">3. 样本分数区间坏样本率校准</h2><p>评分卡校准后，可以得到每个样本的校准后概率，但如果涉及到每个分数段的好坏比，该好坏比还是建模样本的而非总体样本的。这是因为在模型校准过程虽然校准了每个客户违约概率的值，即整个违约概率值分布发生了变化，但是并不会改变评分模型的排序顺序，在训练样本里相应的得分区间，还是有那么多坏用户。<br />因此对计算出来的各个分数段的好坏用户也需要校准，特别是在进行利率定价时，需要计算风险成本时，需要还原到产品真实的违约概率水平。<br />&gt; 校准步骤如下：<br />+ S1：产品真实样本坏好比=产品最终真实坏用户数/产品最终真实好用户数 +S2：建模样本坏好比=建模样本坏用户数/建模样本好用户数 +S3：调整因子=ln(产品真实样本坏好比/建模样本坏好比) +S4：每箱坏好比自然对数=ln(每箱坏用户数/每箱好用户数) +S5：调整后每箱坏好比自然对数=每箱坏好比自然对数+调整因子 +S6：每箱还原后坏用户占比(校准后违约概率)=1/(1+e^-调整后每箱坏好比自然对数)</p><p>校准示例如下： <imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/202200613_jiaozhun.png" /></p>]]></content>
      
      
      <categories>
          
          <category> 信贷风控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 评分卡 </tag>
            
            <tag> 信贷风控 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker深度学习环境配置</title>
      <link href="/2022/06/10/docker-shen-du-xue-xi-huan-jing-pei-zhi/"/>
      <url>/2022/06/10/docker-shen-du-xue-xi-huan-jing-pei-zhi/</url>
      
        <content type="html"><![CDATA[<h1 id="docker深度学习环境配置及使用">docker深度学习环境配置及使用</h1><blockquote><p>目标：该文章用于记录ubuntu18.04下深度学习环境配置流程，以及记录docker常用命令</p></blockquote><h2 id="深度学习环境配置">1. 深度学习环境配置</h2><h2 id="docker环境配置">1.1 docker环境配置</h2><h3 id="docker安装">1.1.1 docker安装</h3><ol type="1"><li>教程<ahref="https://www.runoob.com/docker/ubuntu-docker-install.html">UbuntuDocker 安装</a></li><li>使用官方安装脚本自动安装，命令如下： <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">curl</span> -fsSL https://get.docker.com <span class="token operator">|</span> <span class="token function">bash</span> -s <span class="token function">docker</span> --mirror Aliyun<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><h3 id="设置非root账号不用sudo直接执行docker命令">1.1.2设置非root账号不用sudo直接执行docker命令</h3><h4 id="现状">1.1.2.1 现状</h4><ol type="1"><li><p>报错如下： <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hehe@heheomg:~$ <span class="token function">docker</span> imagesGot permission denied <span class="token keyword">while</span> trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/images/json: dial unix /var/run/docker.sock:connect: permission denied<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre> #### 1.1.2.2 解决方案</p></li><li><p>创建名为docker的组，如果之前已经有该组就会报错，可以忽略这个错误：<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">groupadd</span> <span class="token function">docker</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p></li><li><p>将当前用户加入组docker： <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> gpasswd -a <span class="token variable">$&#123;<span class="token environment constant">USER</span>&#125;</span> <span class="token function">docker</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p></li><li><p>重启docker服务(生产环境请慎用)： <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> systemctl restart <span class="token function">docker</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p></li><li><p>给docker.sock添加权限 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">chmod</span> a+rw /var/run/docker.sock<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre> ## 1.2 安装GPU显卡驱动 ###1.2.1 检测NVIDIA显卡型号和推荐的驱动安装型号</p></li><li><p>命令如下： <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ubuntu-drivers devices<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre> <imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/20220610_nvidia_01.png"alt="20220610_nvidia_01" /></p></li></ol><ul><li>从上图中可知，目前系统已连接Nvidia GeForce RTX 2070显卡，建议安装驱动程序是 nvidia-510版本的驱动</li></ul><ol start="2" type="1"><li>安装驱动命令: <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> nvidia-driver-510<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><ul><li>安装完成后重启系统</li></ul><ol start="3" type="1"><li>检查是否安装成功: <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">nvidia-smi<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre> <imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/20220610_nvidia_02.png"alt="20220610_nvidia_02" /></li></ol><h2 id="docker深度学习环境配置">1.3 docker深度学习环境配置</h2><ol type="1"><li><p>docker镜像：<ahref="https://hub.docker.com/r/ufoym/deepo">ufoym/deepo</a></p></li><li><p>拉取docker镜像: <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> pull ufoym/deepo<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p></li><li><p>启动容器，同时启动jupyter notebook <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> run --gpus all -it -p <span class="token number">8888</span>:8888 --ipc<span class="token operator">=</span>host -v path1:path2 ufoym/deepo jupyter notebook --no-browser --ip<span class="token operator">=</span><span class="token number">0.0</span>.0.0 --allow-root --NotebookApp.token<span class="token operator">=</span> --notebook-dir<span class="token operator">=</span><span class="token string">'/root'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre> &gt; +-i：以交互模式运行容器，通常与 -t 同时使用； &gt; + --gpus:使用gpu，--gpus all所有gpu, 数字，--gpus 2表示使用两个gpu，指定gpu，如--gpus '"device=1,2"' &gt; + -t:为容器重新分配一个伪输入终端，通常与 -i 同时使用； &gt; + -p:指定端口映射，格式为：主机(宿主)端口:容器端口. &gt; + --ipc host:开放内存容器相互之间，以及与主机之间都能进行内存共享。 &gt; +-v：path1为服务器上挂载地址，path2为映射到容器中的地址</p></li><li><p>退出容器.<br /></p></li></ol><ol type="a"><li>按Ctrl+P+Q退出容器但不关闭<br /></li><li>exit退出容器且关闭</li></ol><ol start="5" type="1"><li><p>本地连接jupyternotebook,浏览器输入127.0.0.1：8888；远程计算机连接服务器jupyternotebook, 浏览器输入服务器ip及其端口，如ip:8888</p></li><li><p>PS: 新增以下解释 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">jupyter notebook --no-browser --ip<span class="token operator">=</span><span class="token number">0.0</span>.0.0 --allow-root --NotebookApp.token<span class="token operator">=</span> --notebook-dir<span class="token operator">=</span><span class="token string">'/root'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre> &gt; + jupyter notebook--no-browser : 启动，但不用弹出网页 &gt; + jupyter notebook --ip=0.0.0.0: 公网启动 &gt; + jupyter notebook --NotebookApp.token='123456'启动并设置 Token &gt; + jupyter notebook --notebook-dir='/root' :指定启动目录 &gt; + jupyter notebook --allow-root :使用root用户启动</p></li></ol><h2 id="docker常用命令">1.4 docker常用命令</h2><ol type="1"><li><p>查看docker版本信息.<br /><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> version<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p></li><li><p>查看docker的系统信息.<br /><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> info<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p></li><li><p>显示可用的镜像.<br /><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> images <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p></li><li><p>删除指定镜像.<br /><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> rmi <span class="token operator">&lt;</span>镜像Id<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p></li><li><p>查看容器.<br /><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> <span class="token function">ps</span> <span class="token punctuation">[</span>OPTIONS<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre> &gt; + -a :显示所有的容器，包括未运行的。<br />&gt; + -f :根据条件过滤显示的内容。<br />&gt; + --format :指定返回值的模板文件。<br />&gt; + -l :显示最近创建的容器。<br />&gt; + -n :列出最近创建的n个容器。<br />&gt; + --no-trunc :不截断输出。<br />&gt; + -q :静默模式，只显示容器编号。<br />&gt; + -s :显示总的文件大小。</p></li><li><p>停止指定的容器.<br /><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> stop container_id/container-name<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p></li><li><p>启动容器.<br /><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> start container_id/container-name<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p></li><li><p>重启容器.<br /><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> restart container_id/container-name<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p></li><li><p>删除容器.<br /><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> <span class="token function">rm</span> container_id/container-name<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p></li><li><p>批量删除容器,删除所有运行结束了容器,正在运行的容器不会被删除.<br /><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> <span class="token function">rm</span> <span class="token variable"><span class="token variable">$(</span><span class="token function">docker</span> <span class="token function">ps</span> -a -q<span class="token variable">)</span></span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p></li><li><p>连接到正在运行中的容器.<br /><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> attach container_id/container-name<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
            <tag> 环境配置 </tag>
            
            <tag> ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图像分类丨ILSVRC历届冠军网络「从AlexNet到SENet」</title>
      <link href="/2022/06/09/tu-xiang-fen-lei-gun-ilsvrc-li-jie-guan-jun-wang-luo-cong-alexnet-dao-senet/"/>
      <url>/2022/06/09/tu-xiang-fen-lei-gun-ilsvrc-li-jie-guan-jun-wang-luo-cong-alexnet-dao-senet/</url>
      
        <content type="html"><![CDATA[<h1 id="图像分类-ilsvrc历届冠军网络从alexnet到senet"><ahref="https://www.cnblogs.com/vincent1997/p/10901875.html">图像分类 |ILSVRC历届冠军网络[从AlexNet到SENet]</a></h1><blockquote><p>该文属于转载，由于时间久远，找不到初始作者了，特此说明</p></blockquote><h2 id="前言">前言</h2><ul><li>深度卷积网络极大地推进深度学习各领域的发展，ILSVRC作为最具影响力的竞赛功不可没，促使了许多金典工作。我梳理了ILSVRC分类任务的各界冠军和亚军网络，简单介绍了它们的核心思想、网络框架及其实现。<br />代码主要来自：<ahref="https://github.com/weiaicunzai/pytorch-cifar100">https://github.com/weiaicunzai/pytorch-cifar100</a></li><li>ImageNet和ILSVRC<ul><li>ImageNet是一个超过15 million的图像数据集，大约有22,000类。</li><li>ILSVRC全称ImageNet Large-Scale Visual Recognition Challenge,从2010年开始举办到2017年最后一届，使用ImageNet数据集的一个子集，总共有1000类。</li></ul></li><li>历届结果</li></ul><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/1.jpg" /><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/2.PNG" /></p><p>ps: 上表和真实指标可能略有差距。 + 评价指标<br />top1是指概率向量最大的作为预测结果，若分类正确，则为正确；top5则只要概率向量中最大的前五名里有分类正确的，则为正确。</p><h2 id="lenet">LeNet</h2><p><ahref="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf">Gradient-BasedLearning Applied to Document Recognition</a> ### 网络架构 <imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/6.png" /></p><ul><li>代码实现</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> func<span class="token keyword">class</span> <span class="token class-name">LeNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>LeNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">16</span><span class="token punctuation">,</span>  <span class="token number">120</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> func<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> func<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> func<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> func<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> func<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> func<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> func<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="alexnet">AlexNet</h2><p><ahref="https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">ImageNetClassification with Deep Convolutional Neural Networks</a> ### 核心思想+ AlexNet相比前人有以下改进： + 采用ReLU激活函数 + 局部响应归一化LRN</p><pre><code>    ![](https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/3.PNG)+ Overlapping Pooling+ 引入Drop out+ 数据增强+ 多GPU并行</code></pre><h3 id="网络架构">网络架构</h3><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/4.png" />+ 代码实现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">AlexNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_classes <span class="token operator">=</span> NUM_CLASSES<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>AlexNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init<span class="token punctuation">(</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>num_classes <span class="token operator">=</span> num_classes                self<span class="token punctuation">.</span>features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">11</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span> <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">256</span> <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="实验结果">实验结果</h3><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/5.png" /></p><h2 id="zfnet">ZFNet</h2><p><a href="https://arxiv.org/pdf/1311.2901.pdf">Visualizing andUnderstanding Convolutional Networks</a></p><h3 id="核心思想">核心思想</h3><ul><li>利用反卷积可视化CNN学到的特征<ul><li>Unpooling:池化操作不可逆，但通过记录池化最大值的位置可实现逆操作。</li><li>Rectification: ReLU</li><li>Fitering: 使用原卷积核的转置版本 <imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/7.png" /></li></ul></li></ul><h3 id="网络架构-1">网络架构</h3><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/8.png" /></p><h3 id="实验结果-1">实验结果</h3><ul><li>特征可视化：Layer2响应角落和边缘、颜色连接；Layer3有更复杂的不变性，捕获相似纹理；Layer4展示了明显的变化，跟类别更相关；Layer5看到整个物体。</li></ul><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/9.png" />+训练过程特征演化：低层特征较快收敛，高层到后面才开始变化。上面每层从左到右训练次数为1，2，5，10，20，30，40，64个epoch。</p><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/10.png" />+特征不变性：小变换在模型第一层变化明显，但在顶层影响较小。网络输出对翻转和缩放是稳定的，但除了旋转对称性的物体，输出对旋转并不是不变的。+ 遮挡敏感性： 当对象被遮挡，准确性会明显下降 + ImageNet结果</p><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/11.png" /></p><h2 id="vgg">VGG</h2><p><a href="https://arxiv.org/abs/1409.1556v6">Very Deep ConvolutionalNetworks for Large-Scale Image Recognition</a> ### 核心思想 +重复使用3x3卷积和2x2池化增加网络深度。</p><h3 id="网络架构-2">网络架构</h3><ul><li>VGG19表示19层conv或fc,参数量较大。</li></ul><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/12.png" /></p><h3 id="代码实现">代码实现</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">cfg <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token string">'A'</span> <span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span>     <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span>      <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span>            <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span>           <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span>           <span class="token string">'M'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token string">'B'</span> <span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span>           <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span>           <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span>           <span class="token string">'M'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token string">'D'</span> <span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span>      <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span>      <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span>      <span class="token string">'M'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token string">'E'</span> <span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">&#125;</span><span class="token keyword">def</span> <span class="token function">vgg19_bn</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> VGG<span class="token punctuation">(</span>make_layers<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">'E'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> batch_norm<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">VGG</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> features<span class="token punctuation">,</span> num_class <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>features <span class="token operator">=</span> features                 self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> num_class<span class="token punctuation">)</span>        <span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        output <span class="token operator">=</span> output<span class="token punctuation">.</span>view<span class="token punctuation">(</span>output<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>output<span class="token punctuation">)</span>        <span class="token keyword">return</span> output        <span class="token keyword">def</span> <span class="token function">make_layers</span><span class="token punctuation">(</span>cfg<span class="token punctuation">,</span> batch_norm<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                input_channel <span class="token operator">=</span> <span class="token number">3</span>        <span class="token keyword">for</span> l <span class="token keyword">in</span> cfg<span class="token punctuation">:</span>            <span class="token keyword">if</span> l <span class="token operator">==</span> <span class="token string">'M'</span><span class="token punctuation">:</span>                layers <span class="token operator">+=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span>                <span class="token keyword">continue</span>                        layers <span class="token operator">+=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>input_channel<span class="token punctuation">,</span> l<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>                        <span class="token keyword">if</span> batch_norm<span class="token punctuation">:</span>                layers <span class="token operator">+=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">]</span>                        layers <span class="token operator">+=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            input_channel <span class="token operator">=</span> <span class="token number">1</span>        <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>layers<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="实验结果-2">实验结果</h3><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/13.png" /></p><h2 id="googlenetv1">GoogLeNet(V1)</h2><p><a href="https://arxiv.org/abs/1409.4842v1">Going Deeper withConvolutions</a></p><p>ps: <ahref="https://blog.csdn.net/weixin_39953502/article/details/80966046">https://blog.csdn.net/weixin_39953502/article/details/80966046</a></p><h3 id="核心思想-1">核心思想</h3><ul><li>提出Inception模块，可在保持计算成本的同时增加网络的深度和宽度。 <imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/14.png" /></li></ul><h3 id="代码实现-1">代码实现</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Inception</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_channels<span class="token punctuation">,</span> n1x1<span class="token punctuation">,</span> n3x3_reduce<span class="token punctuation">,</span> n3x3<span class="token punctuation">,</span> n5x5_reduce<span class="token punctuation">,</span> n5x5<span class="token punctuation">,</span> pool_proj<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token comment">#1x1conv branch</span>        self<span class="token punctuation">.</span>b1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>input_channels<span class="token punctuation">,</span> n1x1<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>n1x1<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>                <span class="token comment">#1x1conv -> 3x3conv branch</span>        self<span class="token punctuation">.</span>b2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>input_channels<span class="token punctuation">,</span> n3x3_reduce<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>n3x3_reduce<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>n3x3_reduce<span class="token punctuation">,</span> n3x3<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>n3x3<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>                <span class="token comment"># 1x1conv -> 5x5conv branch</span>        <span class="token comment"># we use 2 3x3 conv filters stacked instead</span>        <span class="token comment"># of 1 5x5filters to obtain the same receptive</span>        <span class="token comment"># field with fewer parameters</span>        self<span class="token punctuation">.</span>b3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>input_channels<span class="token punctuation">,</span> n5x5_reduce<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>n5x5_reduce<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>n5x5_reduce<span class="token punctuation">,</span> n5x5<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>n5x5<span class="token punctuation">,</span> n5x5<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>n5x5<span class="token punctuation">,</span> n5x5<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>n5x5<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>                <span class="token comment"># 3x3pooling ->1x1conv</span>        <span class="token comment"># same conv</span>        self<span class="token punctuation">.</span>b4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> stride <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>input_channels<span class="token punctuation">,</span> pool_proj<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>pool_proj<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>b1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>b2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>b3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>b4<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="网络架构-3">网络架构</h3><blockquote><p>高清图看论文</p></blockquote><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/15.png" /><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/16.png" /></p><h3 id="代码实现-2">代码实现</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">googlenet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> GoogleNet<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">GoogleNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_class<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>prelayer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">192</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>                <span class="token comment"># although we only use 1 conv layer as prelayer,</span>        <span class="token comment"># we stil use name a3, b3...</span>        self<span class="token punctuation">.</span>a3 <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>b3 <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>                <span class="token comment"># In general, an Inception network is a network consisting of</span>        <span class="token comment"># modules of the above type stacked upon each other, with occasional</span>        <span class="token comment"># max-pooling layers with stride 2 to halve the resolution of the grid</span>        self<span class="token punctuation">.</span>maxpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>a4 <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">480</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">208</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>b4 <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">160</span><span class="token punctuation">,</span> <span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>c4 <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>d4 <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">144</span><span class="token punctuation">,</span> <span class="token number">288</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>e4 <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">528</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">160</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>a5 <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">832</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">160</span><span class="token punctuation">,</span> <span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>b5 <span class="token operator">=</span> Inception<span class="token punctuation">(</span><span class="token number">832</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">,</span> <span class="token number">284</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>                <span class="token comment"># input feature size: 8*8*1024</span>        self<span class="token punctuation">.</span>avgpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> num_class<span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>prelayer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>a3<span class="token punctuation">(</span>output<span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>b3<span class="token punctuation">(</span>output<span class="token punctuation">)</span>                output <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool<span class="token punctuation">(</span>output<span class="token punctuation">)</span>                output <span class="token operator">=</span> self<span class="token punctuation">.</span>a5<span class="token punctuation">(</span>output<span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>b5<span class="token punctuation">(</span>output<span class="token punctuation">)</span>                <span class="token comment"># It was found that a move from fully connected layers </span>        <span class="token comment"># to average pooling imporved the top-1 accuracy by about 0.6%,</span>        <span class="token comment"># however the use of dorpout remained essential even after</span>        <span class="token comment"># removing the fully connected layers.</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>avgpool<span class="token punctuation">(</span>output<span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>output<span class="token punctuation">)</span>        output <span class="token operator">=</span> output<span class="token punctuation">.</span>view<span class="token punctuation">(</span>output<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>output<span class="token punctuation">)</span>                <span class="token keyword">return</span> output<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="实验结果-3">实验结果</h3><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/17.png" /></p><h2 id="resnet">ResNet</h2><p><a href="https://arxiv.org/abs/1512.03385v1">Deep Residual Learningfor Image Recognition</a></p><h3 id="核心思想-2">核心思想</h3><ul><li>为了解决深层网络难以训练的问题，提出了残差模块和深度残差网络<ul><li>假设网络输入是x，经学习的输出是F(x),最终拟合的目标是H(x)。</li><li>深层网络相比浅层网络有一些层是多余的，若让多余层学习恒等变换H(x)=x，那么网络性能不该比浅层网络要差。</li><li>传统网络训练目标H(x)= F(x), 残差网络训练目标H(x)=F(x) + x</li><li>为了学习恒等变换，传统网络要求网络学习F(x) = H(x) = x，残差网络只需学习F(x) = H(x)-x = x-x = 0.残差学习之所以有效是因为让网络学习F(x) = 0比学习F(x)=x要容易。</li></ul></li></ul><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/18.png" /></p><ul><li>bottleneck</li></ul><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/19.jpg" /></p><ul><li>代码实现</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">BottleNeck</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Residual block for resnet over 50 layers    """</span>    expansion <span class="token operator">=</span> <span class="token number">4</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> stride <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>residual_function <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> bias <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> stride <span class="token operator">=</span> stride<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> bias <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token operator">*</span>BottleNeck<span class="token punctuation">.</span>expansion<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels <span class="token operator">*</span> BottleNeck<span class="token punctuation">.</span>expansion<span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>                self<span class="token punctuation">.</span>shortcut <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> stride <span class="token operator">!=</span> <span class="token number">1</span> <span class="token keyword">or</span> inchannels <span class="token operator">!=</span> out_channels <span class="token operator">*</span> BottleNeck<span class="token punctuation">.</span>expansion<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>shortcut <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels <span class="token operator">*</span> BottleNeck<span class="token punctuation">.</span>expansion<span class="token punctuation">,</span> stride <span class="token operator">=</span> stride<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token operator">*</span>BottleNeck<span class="token punctuation">.</span>expansion<span class="token punctuation">)</span>            <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>residul_function<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>shortcut<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="网络架构-4">网络架构</h3><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/19.png" /><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/20.png" /></p><h3 id="代码实现-3">代码实现</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">resnet152</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''return a ResNet 152 object    '''</span>    <span class="token keyword">return</span> ResNet<span class="token punctuation">(</span>BottleNeck<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">36</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">ResNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> block<span class="token punctuation">,</span> num_block<span class="token punctuation">,</span> num_classes <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>in_channels <span class="token operator">=</span> <span class="token number">64</span>                self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>COnv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> bias <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        <span class="token comment">#we use a different inputsize than the original paper</span>        <span class="token comment"># so conv2_x's stride is 1</span>        self<span class="token punctuation">.</span>conv2_x <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> num_block<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv3_x <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> num_block<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv4_x <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> num_block<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv5_x <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> num_block<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>avg_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion<span class="token punctuation">,</span> num_classed<span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">_make_layer</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> block<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> num_blocks<span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""make resnet layers(by layer i didnt mean this 'layer' was the         same as a neuron netowork layer, ex. conv layer), one layer may         contain more than one residual block         Args:            block: block type, basic block or bottle neck block            out_channels: output depth channel number of this layer            num_blocks: how many blocks per layer            stride: the stride of the first block of this layer                Return:            return a resnet layer        """</span>                <span class="token comment"># we have num_block blocks per layer, the first block </span>        <span class="token comment"># could be 1 or 2, other blocks would always be 1</span>        strides <span class="token operator">=</span> <span class="token punctuation">[</span>stride<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>num_blocks <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>        layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> stride <span class="token keyword">in</span> strides<span class="token punctuation">:</span>            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>block<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>in_channels <span class="token operator">=</span> out_channels <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion                <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>layers<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2_x<span class="token punctuation">(</span>output<span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3_x<span class="token punctuation">(</span>output<span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>conv4_x<span class="token punctuation">(</span>output<span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>conv5_x<span class="token punctuation">(</span>output<span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>avg_pool<span class="token punctuation">(</span>output<span class="token punctuation">)</span>        output <span class="token operator">=</span> output<span class="token punctuation">.</span>view<span class="token punctuation">(</span>output<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>output<span class="token punctuation">)</span>        <span class="token keyword">return</span> output <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="实验结果-4">实验结果</h3><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/21.png" /></p><h2 id="resnext">ResNext</h2><p><a href="https://arxiv.org/pdf/1611.05431.pdf">Aggregated ResidualTransformations for Deep Neural Networks</a></p><h3 id="核心思想-3">核心思想</h3><ul><li>通过重复构建block来聚合一组相同拓扑结构的特征，并提出一个新维度"cardinality"。</li><li>resNext结合了VGG,ResNet重复堆叠模块和Inception的split-transform-merge的思想。</li></ul><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/22.png" /></p><p>以下三者等价，文章采用第三种实现，其使用了组卷积 <imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/23.png" /></p><ul><li>代码实现</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">CARDINALITY <span class="token operator">=</span> <span class="token number">32</span>DEPTH <span class="token operator">=</span> <span class="token number">4</span>BASEWIDTH <span class="token operator">=</span> <span class="token number">64</span><span class="token keyword">class</span> <span class="token class-name">ResNextBottleNeckC</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        C <span class="token operator">=</span> CARDINALITY <span class="token comment">#How many groups a feature map was splitted into</span>        <span class="token comment">#"""We note that the input/output width of the template is fixed as </span>        <span class="token comment">#256-d (Fig. 3), We note that the input/output width of the template </span>        <span class="token comment">#is fixed as 256-d (Fig. 3), and all widths are dou- bled each time </span>        <span class="token comment">#when the feature map is subsampled (see Table 1)."""</span>        D <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>DEPTH <span class="token operator">*</span> out_channels <span class="token operator">/</span> BASEWIDTH<span class="token punctuation">)</span> <span class="token comment">#number of channels per group</span>        self<span class="token punctuation">.</span>split_transforms <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> C <span class="token operator">*</span> D<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> groups<span class="token operator">=</span>C<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>C <span class="token operator">*</span> D<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>C <span class="token operator">*</span> D<span class="token punctuation">,</span> C <span class="token operator">*</span> D<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> groups<span class="token operator">=</span>C<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>C <span class="token operator">*</span> D<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>C <span class="token operator">*</span> D<span class="token punctuation">,</span> out_channels <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>shortcut <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> stride <span class="token operator">!=</span> <span class="token number">1</span> <span class="token keyword">or</span> in_channels <span class="token operator">!=</span> out_channels <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>shortcut <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span>            <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>split_transforms<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>shortcut<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="网络架构-5">网络架构</h3><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/24.png" /></p><ul><li>代码实现以下部分跟ResNet基本一致，重点关注ResnextBottleNeckC的实现</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">resnext50</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">""" return a resnext50(c32x4d) network    """</span>    <span class="token keyword">return</span> ResNext<span class="token punctuation">(</span>ResNextBottleNeckC<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">ResNext</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> block<span class="token punctuation">,</span> num_blocks<span class="token punctuation">,</span> class_names<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>in_channels <span class="token operator">=</span> <span class="token number">64</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> num_blocks<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> num_blocks<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv4 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> num_blocks<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv5 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_layer<span class="token punctuation">(</span>block<span class="token punctuation">,</span> num_blocks<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>avg <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv5<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>avg<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x        <span class="token keyword">def</span> <span class="token function">_make_layer</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> block<span class="token punctuation">,</span> num_block<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""Building resnext block        Args:            block: block type(default resnext bottleneck c)            num_block: number of blocks per layer            out_channels: output channels per block            stride: block stride                Returns:            a resnext layer        """</span>        strides <span class="token operator">=</span> <span class="token punctuation">[</span>stride<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>num_block <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>        layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> stride <span class="token keyword">in</span> strides<span class="token punctuation">:</span>            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>block<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>in_channels <span class="token operator">=</span> out_channels <span class="token operator">*</span> <span class="token number">4</span>        <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>layers<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="实验结果-5">实验结果</h3><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/25.png" /></p><h2 id="senet">SENet</h2><p><a href="https://arxiv.org/abs/1709.01507">Squeeze-and-ExcitationNetworks</a></p><h3 id="核心思想-4">核心思想</h3><ul><li><p>卷积操作融合了空间和特征通道信息。大量工作研究了空间部分，而本文重点关注特征通道的关系，并提出了Squeeze-and-Excitation(SE)block，对通道间的依赖关系进行建模，自适应校准通道方面的特征响应。</p></li><li><p>SE blockFtr表示transformation（一系列卷积操作）；Fsq表示squeeze，产生通道描述；Fex表示excitation，通过参数W来建模通道的重要性。Fscale表示reweight，将excitation输出的权重逐乘以先前特征，完成特征重标定。</p></li></ul><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/26.png" /></p><ul><li>SE-ResNet Module</li></ul><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/27.png" /></p><ul><li>代码实现</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">BottleneckResidualSEBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    expansion <span class="token operator">=</span> <span class="token number">4</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> stride<span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>residual <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels <span class="token operator">*</span> self<span class="token punctuation">.</span>expansion<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels <span class="token operator">*</span> self<span class="token punctuation">.</span>expansion<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>squeeze <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>excitation <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>out_channels <span class="token operator">*</span> self<span class="token punctuation">.</span>expansion<span class="token punctuation">,</span> out_channels <span class="token operator">*</span> self<span class="token punctuation">.</span>expansion <span class="token operator">//</span> r<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>out_channels <span class="token operator">*</span> self<span class="token punctuation">.</span>expansion <span class="token operator">//</span> r<span class="token punctuation">,</span> out_channels <span class="token operator">*</span> self<span class="token punctuation">.</span>expansion<span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>shortcut <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> stride <span class="token operator">!=</span> <span class="token number">1</span> <span class="token keyword">or</span> in_channels <span class="token operator">!=</span> out_channels <span class="token operator">*</span> self<span class="token punctuation">.</span>expansion<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>shortcut <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels <span class="token operator">*</span> self<span class="token punctuation">.</span>expansion<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>stride<span class="token punctuation">)</span><span class="token punctuation">,</span>                nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels <span class="token operator">*</span> self<span class="token punctuation">.</span>expansion<span class="token punctuation">)</span>            <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        shortcut <span class="token operator">=</span> self<span class="token punctuation">.</span>shortcut<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        residual <span class="token operator">=</span> self<span class="token punctuation">.</span>residual<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        squeeze <span class="token operator">=</span> self<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>residual<span class="token punctuation">)</span>        squeeze <span class="token operator">=</span> squeeze<span class="token punctuation">.</span>view<span class="token punctuation">(</span>squeeze<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        excitation <span class="token operator">=</span> self<span class="token punctuation">.</span>excitation<span class="token punctuation">(</span>squeeze<span class="token punctuation">)</span>        excitation <span class="token operator">=</span> excitation<span class="token punctuation">.</span>view<span class="token punctuation">(</span>residual<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> residual<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> residual <span class="token operator">*</span> excitation<span class="token punctuation">.</span>expand_as<span class="token punctuation">(</span>residual<span class="token punctuation">)</span> <span class="token operator">+</span> shortcut        <span class="token keyword">return</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="网络架构-6">网络架构</h3><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/28.png" /></p><ul><li>代码实现</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">seresnet50</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> SEResNet<span class="token punctuation">(</span>BottleneckResidualSEBlock<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">SEResNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> block<span class="token punctuation">,</span> block_num<span class="token punctuation">,</span> class_num<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>in_channels <span class="token operator">=</span> <span class="token number">64</span>        self<span class="token punctuation">.</span>pre <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>stage1 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_stage<span class="token punctuation">(</span>block<span class="token punctuation">,</span> block_num<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>stage2 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_stage<span class="token punctuation">(</span>block<span class="token punctuation">,</span> block_num<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>stage3 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_stage<span class="token punctuation">(</span>block<span class="token punctuation">,</span> block_num<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>stage4 <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_stage<span class="token punctuation">(</span>block<span class="token punctuation">,</span> block_num<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">516</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channels<span class="token punctuation">,</span> class_num<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pre<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>stage1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>stage2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>stage3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>stage4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>adaptive_avg_pool2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x        <span class="token keyword">def</span> <span class="token function">_make_stage</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> block<span class="token punctuation">,</span> num<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">:</span>        layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>block<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>in_channels <span class="token operator">=</span> out_channels <span class="token operator">*</span> block<span class="token punctuation">.</span>expansion        <span class="token keyword">while</span> num <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">:</span>            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>block<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            num <span class="token operator">-=</span> <span class="token number">1</span>                <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>layers<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>实验结果</li></ul><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/29.png" /></p><h2 id="总结">总结</h2><ul><li>小结<ol type="1"><li>LeNet[1998]：CNN的鼻祖。</li><li>AlexNet[2012]：第一个深度CNN。</li><li>ZFNet[2012]：通过DeconvNet可视化CNN学习到的特征。</li><li>VGG[2014]：重复堆叠3x3卷积增加网络深度。</li><li>GoogLeNet[2014]：提出Inception模块，在控制参数和计算量的前提下，增加网络的深度与宽度。</li><li>ResNet[2015]：提出残差网络，解决了深层网络的优化问题。</li><li>ResNeXt[2016]：ResNet和Inception的结合体，Inception中每个分支结构相同，无需人为设计。</li><li>SENet[2017]：提出SE block，关注特征的通道关系。</li></ol></li><li>经典模型结构中、参数对比</li></ul><p><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/30.jpg" /></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VGG</title>
      <link href="/2022/06/09/vgg/"/>
      <url>/2022/06/09/vgg/</url>
      
        <content type="html"><![CDATA[<h1 id="vgg">VGG</h1><h3 id="参考">参考</h3><p>1.<a href="https://arxiv.org/abs/1409.1556">Very Deep ConvolutionalNetworks for Large-Scale Image Recognition</a><br />2.<ahref="https://www.cnblogs.com/lfri/p/10493408.html">VGG16学习笔记</a></p><h2 id="模型组成">1. 模型组成</h2><ol type="1"><li>input: 224 x 224 RGB image</li><li>preprocessing: the mean RGB value, computed ont the training set,from each pixel</li><li>组件： 3 x 3 convolution filters, 1 x 1 convolution filters</li><li>In one of the configurations we also utilise 1 x 1 convolutionfilters, which can be seen as a linear transformation of the inputchannels(followed by non-linearity)</li><li>the convolution stride is fixed to 1 pixel; the spatial padding ofconv.layer input is such that the spatial resolution is preserved afterconvolution, i.e the padding is 1 pixel for 3 x 3 conv.layers.</li><li>Spatial pooling is carried out by five max-pooling layers, whichfollow some of the conv.layers(not all the conv.layers are followed bymax-pooling).Max-pooling is performed over a 2 x 2 pixel window, witstride 2.</li><li>A stack of convolutional layers(which has a different depth indifferent architectures) if followed by three Fully-Connected(FC)lyaers: the first two have 4096 channels each, the final layer is thesoft-max layer.</li><li>the configuration of the fully connected layers is the same in allnetworks</li><li>all hidden layers ate equipped with the rectification(ReLU)non-linearity.</li></ol><h2 id="模型详细结构">2. 模型详细结构</h2><p>VGG中根据卷积核大小和卷积层数目的不同，可分为A，A-LRN,B,C,D,E共6个配置(ConvNetConfiguration)，其中以D,E两种配置较为常用，分别称为VGG16和VGG19。</p><p>下图给出了VGG的六种结构配置： <imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/VGG_networks.PNG"alt="VGG_networks" /></p><p>上图中，每一列对应一种结构配置。例如，图中绿色部分即指明了VGG16所采用的结构。</p><p>我们针对VGG16进行具体分析发现，VGG16共包含：</p><ul><li><p>13个卷积层（Convolutional Layer），分别用conv3-XXX表示</p></li><li><p>3个全连接层（Fully connected Layer）,分别用FC-XXXX表示</p></li><li><p>5个池化层（Pool layer）,分别用maxpool表示其中，卷积层和全连接层具有权重系数，因此也被称为权重层，总数目为13+3=16，这即是</p></li></ul><p>VGG16中16的来源。(池化层不涉及权重，因此不属于权重层，不被计数)。</p><h2 id="特点">3. 特点</h2><p>VGG16的突出特点是简单，体现在：</p><p>卷积层均采用相同的卷积核参数</p><ol type="1"><li><p>卷积层均表示为conv3-XXX，其中conv3说明该卷积层采用的卷积核的尺寸(kernelsize)是3，即宽（width）和高（height）均为3，3*3是很小的卷积核尺寸，结合其它参数（步幅stride=1，填充方式padding=same），这样就能够使得每一个卷积层(张量)与前一层（张量）保持相同的宽和高。XXX代表卷积层的通道数。</p></li><li><p>池化层均采用相同的池化核参数</p></li><li><p>池化层的参数均为2×</p></li></ol><p>模型是由若干卷积层和池化层堆叠（stack）的方式构成，比较容易形成较深的网络结构（在2014年，16层已经被认为很深了）。</p><p>综合上述分析，可以概括VGG的优点为: Small filters, Deepernetworks.</p><figure><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/vgg16.PNG"alt="vgg16" /><figcaption aria-hidden="true">vgg16</figcaption></figure><h2 id="块结构">4. 块结构</h2><p>下面给出按照块划分的VGG16的结构图：</p><figure><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/vgg16-2.PNG"alt="vgg16-2" /><figcaption aria-hidden="true">vgg16-2</figcaption></figure><p>VGG的输入图像是 224x224x3</p><ul><li>通道数翻倍，由64依次增加到128，再到256，直至512保持不变，不再翻倍</li><li>高和宽变减半，由 224→112→56→28→14→7</li></ul><h2 id="权重参数">5. 权重参数</h2><p>尽管VGG的结构简单，但是所包含的权重数目却很大，达到了惊人的139，357，544个参数。这些参数包括卷积核权重和全连接层权重。</p><ul><li>例如，对于第一层卷积，由于输入图的通道数是3，网络必须学习大小为3x3，通道数为3的的卷积核，这样的卷积核有64个，因此总共有（3x3x3）x64= 1728个参数</li><li>计算全连接层的权重参数数目的方法为：前一层节点数×本层的节点数前一层节点数×本层的节点数。因此，全连接层的参数分别为：<ul><li>7x7x512x4096 = 1027,645,444</li><li>4096x4096 = 16,781,321</li><li>4096x1000 = 4096000<br />FeiFeiLi在CS231的课件中给出了整个网络的全部参数的计算过程（不考虑偏置），如下图所示：</li></ul></li></ul><figure><imgsrc="https://imgs-heheomg.oss-cn-hangzhou.aliyuncs.com/blog_imgs/vgg_weight.png"alt="vgg_weight" /><figcaption aria-hidden="true">vgg_weight</figcaption></figure><p>图中蓝色是计算权重参数数量的部分；红色是计算所需存储容量的部分。</p><p>VGG16具有如此之大的参数数目，可以预期它具有很高的拟合能力；但同时缺点也很明显：</p><ul><li>即训练时间过长，调参难度大。</li><li>需要的存储容量大，不利于部署。例如存储VGG16权重值文件的大小为500多MB，不利于安装到嵌入式系统中。</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">from</span> typing <span class="token keyword">import</span> Union<span class="token punctuation">,</span> List<span class="token punctuation">,</span> Dict<span class="token punctuation">,</span> Any<span class="token punctuation">,</span> cast<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">__all__ <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token string">'VGG'</span><span class="token punctuation">,</span> <span class="token string">'vgg11'</span><span class="token punctuation">,</span> <span class="token string">'vgg11_bn'</span><span class="token punctuation">,</span> <span class="token string">'vgg13'</span><span class="token punctuation">,</span> <span class="token string">'vgg13_bn'</span><span class="token punctuation">,</span> <span class="token string">'vgg16'</span><span class="token punctuation">,</span> <span class="token string">'vgg16_bn'</span><span class="token punctuation">,</span>    <span class="token string">'vgg19_bn'</span><span class="token punctuation">,</span> <span class="token string">'vgg19'</span><span class="token punctuation">,</span><span class="token punctuation">]</span>model_urls <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token string">'vgg11'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/vgg11-bbd30ac9.pth'</span><span class="token punctuation">,</span>    <span class="token string">'vgg13'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/vgg13-c768596a.pth'</span><span class="token punctuation">,</span>    <span class="token string">'vgg16'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/vgg16-397923af.pth'</span><span class="token punctuation">,</span>    <span class="token string">'vgg19'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth'</span><span class="token punctuation">,</span>    <span class="token string">'vgg11_bn'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/vgg11_bn-6002323d.pth'</span><span class="token punctuation">,</span>    <span class="token string">'vgg13_bn'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth'</span><span class="token punctuation">,</span>    <span class="token string">'vgg16_bn'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth'</span><span class="token punctuation">,</span>    <span class="token string">'vgg19_bn'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth'</span><span class="token punctuation">,</span><span class="token punctuation">&#125;</span><span class="token keyword">class</span> <span class="token class-name">VGG</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>        self<span class="token punctuation">,</span>        features<span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Module<span class="token punctuation">,</span>        num_classes<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span>        init_weights<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span>    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>VGG<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>features <span class="token operator">=</span> features        self<span class="token punctuation">.</span>avgpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>        <span class="token keyword">if</span> init_weights<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>_initialize_weights<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>avgpool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x        <span class="token keyword">def</span> <span class="token function">_initialize_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token boolean">None</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> m  <span class="token keyword">in</span> self<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'fan_out'</span><span class="token punctuation">,</span> nonlinearity<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> m<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>                    nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>            <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span><span class="token punctuation">:</span>                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>            <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">)</span>                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>                <span class="token keyword">def</span> <span class="token function">make_layers</span><span class="token punctuation">(</span>cfg<span class="token punctuation">:</span> List<span class="token punctuation">[</span>Union<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> batch_norm<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">:</span>    layers<span class="token punctuation">:</span> List<span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    in_channels <span class="token operator">=</span> <span class="token number">3</span>    <span class="token keyword">for</span> v <span class="token keyword">in</span> cfg<span class="token punctuation">:</span>        <span class="token keyword">if</span> v <span class="token operator">==</span> <span class="token string">'M'</span><span class="token punctuation">:</span>            layers <span class="token operator">+=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            v <span class="token operator">=</span> cast<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">,</span> v<span class="token punctuation">)</span>            conv2d <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> v<span class="token punctuation">,</span> kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> padding  <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> batch_norm<span class="token punctuation">:</span>                layers <span class="token operator">+=</span> <span class="token punctuation">[</span>conv2d<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>v<span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                layers <span class="token operator">+=</span> <span class="token punctuation">[</span>conv2d<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            in_channels <span class="token operator">=</span> v    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>layers<span class="token punctuation">)</span>cfgs<span class="token punctuation">:</span> Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> List<span class="token punctuation">[</span>Union<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span>    <span class="token string">'A'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token string">'B'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token string">'D'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token string">'E'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">&#125;</span>    <span class="token keyword">def</span> <span class="token function">_vgg</span><span class="token punctuation">(</span>arch<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> cfg<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> batch_norm<span class="token punctuation">:</span> <span class="token builtin">bool</span><span class="token punctuation">,</span> pretrained<span class="token punctuation">:</span> <span class="token builtin">bool</span><span class="token punctuation">,</span> progress<span class="token punctuation">:</span> <span class="token builtin">bool</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> VGG<span class="token punctuation">:</span>    <span class="token keyword">if</span> pretrained<span class="token punctuation">:</span>        kwargs<span class="token punctuation">[</span><span class="token string">'init_weights'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>    model <span class="token operator">=</span> VGG<span class="token punctuation">(</span>make_layers<span class="token punctuation">(</span>cfgs<span class="token punctuation">[</span>cfg<span class="token punctuation">]</span><span class="token punctuation">,</span> batch_norm<span class="token operator">=</span>batch_norm<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>    <span class="token keyword">if</span> pretrained<span class="token punctuation">:</span>        state_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>hub<span class="token punctuation">.</span>load_state_dict_from_url<span class="token punctuation">(</span>model_urls<span class="token punctuation">[</span>arch<span class="token punctuation">]</span><span class="token punctuation">,</span>                                              progress<span class="token operator">=</span>progress<span class="token punctuation">)</span>        model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>state_dict<span class="token punctuation">)</span>    <span class="token keyword">return</span> model<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">vgg11</span><span class="token punctuation">(</span>pretrained<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> progress<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> VGG<span class="token punctuation">:</span>    <span class="token triple-quoted-string string">r"""VGG 11-layer model (configuration "A") from    `"Very Deep Convolutional Networks For Large-Scale Image Recognition" &lt;https://arxiv.org/pdf/1409.1556.pdf>`_    Args:        pretrained (bool): If True, returns a model pre-trained on ImageNet        progress (bool): If True, displays a progress bar of the download to stderr    """</span>    <span class="token keyword">return</span> _vgg<span class="token punctuation">(</span><span class="token string">'vgg11'</span><span class="token punctuation">,</span> <span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> pretrained<span class="token punctuation">,</span> progress<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">vgg11_bn</span><span class="token punctuation">(</span>pretrained<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> progress<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> VGG<span class="token punctuation">:</span>    <span class="token triple-quoted-string string">r"""VGG 11-layer model (configuration "A") with batch normalization    `"Very Deep Convolutional Networks For Large-Scale Image Recognition" &lt;https://arxiv.org/pdf/1409.1556.pdf>`_    Args:        pretrained (bool): If True, returns a model pre-trained on ImageNet        progress (bool): If True, displays a progress bar of the download to stderr    """</span>    <span class="token keyword">return</span> _vgg<span class="token punctuation">(</span><span class="token string">'vgg11_bn'</span><span class="token punctuation">,</span> <span class="token string">'A'</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">,</span> pretrained<span class="token punctuation">,</span> progress<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">vgg13</span><span class="token punctuation">(</span>pretrained<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> progress<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> VGG<span class="token punctuation">:</span>    <span class="token triple-quoted-string string">r"""VGG 13-layer model (configuration "B")    `"Very Deep Convolutional Networks For Large-Scale Image Recognition" &lt;https://arxiv.org/pdf/1409.1556.pdf>`_    Args:        pretrained (bool): If True, returns a model pre-trained on ImageNet        progress (bool): If True, displays a progress bar of the download to stderr    """</span>    <span class="token keyword">return</span> _vgg<span class="token punctuation">(</span><span class="token string">'vgg13'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> pretrained<span class="token punctuation">,</span> progress<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">vgg13_bn</span><span class="token punctuation">(</span>pretrained<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> progress<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> VGG<span class="token punctuation">:</span>    <span class="token triple-quoted-string string">r"""VGG 13-layer model (configuration "B") with batch normalization    `"Very Deep Convolutional Networks For Large-Scale Image Recognition" &lt;https://arxiv.org/pdf/1409.1556.pdf>`_    Args:        pretrained (bool): If True, returns a model pre-trained on ImageNet        progress (bool): If True, displays a progress bar of the download to stderr    """</span>    <span class="token keyword">return</span> _vgg<span class="token punctuation">(</span><span class="token string">'vgg13_bn'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">,</span> pretrained<span class="token punctuation">,</span> progress<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">vgg16</span><span class="token punctuation">(</span>pretrained<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> progress<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> VGG<span class="token punctuation">:</span>    <span class="token triple-quoted-string string">r"""VGG 16-layer model (configuration "D")    `"Very Deep Convolutional Networks For Large-Scale Image Recognition" &lt;https://arxiv.org/pdf/1409.1556.pdf>`_    Args:        pretrained (bool): If True, returns a model pre-trained on ImageNet        progress (bool): If True, displays a progress bar of the download to stderr    """</span>    <span class="token keyword">return</span> _vgg<span class="token punctuation">(</span><span class="token string">'vgg16'</span><span class="token punctuation">,</span> <span class="token string">'D'</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> pretrained<span class="token punctuation">,</span> progress<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">vgg16_bn</span><span class="token punctuation">(</span>pretrained<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> progress<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> VGG<span class="token punctuation">:</span>    <span class="token triple-quoted-string string">r"""VGG 16-layer model (configuration "D") with batch normalization    `"Very Deep Convolutional Networks For Large-Scale Image Recognition" &lt;https://arxiv.org/pdf/1409.1556.pdf>`_    Args:        pretrained (bool): If True, returns a model pre-trained on ImageNet        progress (bool): If True, displays a progress bar of the download to stderr    """</span>    <span class="token keyword">return</span> _vgg<span class="token punctuation">(</span><span class="token string">'vgg16_bn'</span><span class="token punctuation">,</span> <span class="token string">'D'</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">,</span> pretrained<span class="token punctuation">,</span> progress<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">vgg19</span><span class="token punctuation">(</span>pretrained<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> progress<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> VGG<span class="token punctuation">:</span>    <span class="token triple-quoted-string string">r"""VGG 19-layer model (configuration "E")    `"Very Deep Convolutional Networks For Large-Scale Image Recognition" &lt;https://arxiv.org/pdf/1409.1556.pdf>`_    Args:        pretrained (bool): If True, returns a model pre-trained on ImageNet        progress (bool): If True, displays a progress bar of the download to stderr    """</span>    <span class="token keyword">return</span> _vgg<span class="token punctuation">(</span><span class="token string">'vgg19'</span><span class="token punctuation">,</span> <span class="token string">'E'</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> pretrained<span class="token punctuation">,</span> progress<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">vgg19_bn</span><span class="token punctuation">(</span>pretrained<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> progress<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> VGG<span class="token punctuation">:</span>    <span class="token triple-quoted-string string">r"""VGG 19-layer model (configuration 'E') with batch normalization    `"Very Deep Convolutional Networks For Large-Scale Image Recognition" &lt;https://arxiv.org/pdf/1409.1556.pdf>`_    Args:        pretrained (bool): If True, returns a model pre-trained on ImageNet        progress (bool): If True, displays a progress bar of the download to stderr    """</span>    <span class="token keyword">return</span> _vgg<span class="token punctuation">(</span><span class="token string">'vgg19_bn'</span><span class="token punctuation">,</span> <span class="token string">'E'</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">,</span> pretrained<span class="token punctuation">,</span> progress<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> vgg11<span class="token punctuation">(</span>pretrained<span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">VGG(    <span class="token key atrule">(features)</span><span class="token punctuation">:</span> Sequential(    <span class="token key atrule">(0)</span><span class="token punctuation">:</span> Conv2d(3<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size=(3<span class="token punctuation">,</span> 3)<span class="token punctuation">,</span> stride=(1<span class="token punctuation">,</span> 1)<span class="token punctuation">,</span> padding=(1<span class="token punctuation">,</span> 1))    <span class="token key atrule">(1)</span><span class="token punctuation">:</span> ReLU(inplace=True)    <span class="token key atrule">(2)</span><span class="token punctuation">:</span> MaxPool2d(kernel_size=2<span class="token punctuation">,</span> stride=2<span class="token punctuation">,</span> padding=0<span class="token punctuation">,</span> dilation=1<span class="token punctuation">,</span> ceil_mode=False)    <span class="token key atrule">(3)</span><span class="token punctuation">:</span> Conv2d(64<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size=(3<span class="token punctuation">,</span> 3)<span class="token punctuation">,</span> stride=(1<span class="token punctuation">,</span> 1)<span class="token punctuation">,</span> padding=(1<span class="token punctuation">,</span> 1))    <span class="token key atrule">(4)</span><span class="token punctuation">:</span> ReLU(inplace=True)    <span class="token key atrule">(5)</span><span class="token punctuation">:</span> MaxPool2d(kernel_size=2<span class="token punctuation">,</span> stride=2<span class="token punctuation">,</span> padding=0<span class="token punctuation">,</span> dilation=1<span class="token punctuation">,</span> ceil_mode=False)    <span class="token key atrule">(6)</span><span class="token punctuation">:</span> Conv2d(128<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size=(3<span class="token punctuation">,</span> 3)<span class="token punctuation">,</span> stride=(1<span class="token punctuation">,</span> 1)<span class="token punctuation">,</span> padding=(1<span class="token punctuation">,</span> 1))    <span class="token key atrule">(7)</span><span class="token punctuation">:</span> ReLU(inplace=True)    <span class="token key atrule">(8)</span><span class="token punctuation">:</span> Conv2d(256<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size=(3<span class="token punctuation">,</span> 3)<span class="token punctuation">,</span> stride=(1<span class="token punctuation">,</span> 1)<span class="token punctuation">,</span> padding=(1<span class="token punctuation">,</span> 1))    <span class="token key atrule">(9)</span><span class="token punctuation">:</span> ReLU(inplace=True)    <span class="token key atrule">(10)</span><span class="token punctuation">:</span> MaxPool2d(kernel_size=2<span class="token punctuation">,</span> stride=2<span class="token punctuation">,</span> padding=0<span class="token punctuation">,</span> dilation=1<span class="token punctuation">,</span> ceil_mode=False)    <span class="token key atrule">(11)</span><span class="token punctuation">:</span> Conv2d(256<span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size=(3<span class="token punctuation">,</span> 3)<span class="token punctuation">,</span> stride=(1<span class="token punctuation">,</span> 1)<span class="token punctuation">,</span> padding=(1<span class="token punctuation">,</span> 1))    <span class="token key atrule">(12)</span><span class="token punctuation">:</span> ReLU(inplace=True)    <span class="token key atrule">(13)</span><span class="token punctuation">:</span> Conv2d(512<span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size=(3<span class="token punctuation">,</span> 3)<span class="token punctuation">,</span> stride=(1<span class="token punctuation">,</span> 1)<span class="token punctuation">,</span> padding=(1<span class="token punctuation">,</span> 1))    <span class="token key atrule">(14)</span><span class="token punctuation">:</span> ReLU(inplace=True)    <span class="token key atrule">(15)</span><span class="token punctuation">:</span> MaxPool2d(kernel_size=2<span class="token punctuation">,</span> stride=2<span class="token punctuation">,</span> padding=0<span class="token punctuation">,</span> dilation=1<span class="token punctuation">,</span> ceil_mode=False)    <span class="token key atrule">(16)</span><span class="token punctuation">:</span> Conv2d(512<span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size=(3<span class="token punctuation">,</span> 3)<span class="token punctuation">,</span> stride=(1<span class="token punctuation">,</span> 1)<span class="token punctuation">,</span> padding=(1<span class="token punctuation">,</span> 1))    <span class="token key atrule">(17)</span><span class="token punctuation">:</span> ReLU(inplace=True)    <span class="token key atrule">(18)</span><span class="token punctuation">:</span> Conv2d(512<span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size=(3<span class="token punctuation">,</span> 3)<span class="token punctuation">,</span> stride=(1<span class="token punctuation">,</span> 1)<span class="token punctuation">,</span> padding=(1<span class="token punctuation">,</span> 1))    <span class="token key atrule">(19)</span><span class="token punctuation">:</span> ReLU(inplace=True)    <span class="token key atrule">(20)</span><span class="token punctuation">:</span> MaxPool2d(kernel_size=2<span class="token punctuation">,</span> stride=2<span class="token punctuation">,</span> padding=0<span class="token punctuation">,</span> dilation=1<span class="token punctuation">,</span> ceil_mode=False)    )    <span class="token key atrule">(avgpool)</span><span class="token punctuation">:</span> AdaptiveAvgPool2d(output_size=(7<span class="token punctuation">,</span> 7))    <span class="token key atrule">(classifier)</span><span class="token punctuation">:</span> Sequential(    <span class="token key atrule">(0)</span><span class="token punctuation">:</span> Linear(in_features=25088<span class="token punctuation">,</span> out_features=4096<span class="token punctuation">,</span> bias=True)    <span class="token key atrule">(1)</span><span class="token punctuation">:</span> ReLU(inplace=True)    <span class="token key atrule">(2)</span><span class="token punctuation">:</span> Dropout(p=0.5<span class="token punctuation">,</span> inplace=False)    <span class="token key atrule">(3)</span><span class="token punctuation">:</span> Linear(in_features=4096<span class="token punctuation">,</span> out_features=4096<span class="token punctuation">,</span> bias=True)    <span class="token key atrule">(4)</span><span class="token punctuation">:</span> ReLU(inplace=True)    <span class="token key atrule">(5)</span><span class="token punctuation">:</span> Dropout(p=0.5<span class="token punctuation">,</span> inplace=False)    <span class="token key atrule">(6)</span><span class="token punctuation">:</span> Linear(in_features=4096<span class="token punctuation">,</span> out_features=1000<span class="token punctuation">,</span> bias=True)    ))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># state_dict = torch.hub.load_state_dict_from_url(model_url['vgg11'])</span><span class="token comment"># state_dict.keys()</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CV </tag>
            
            <tag> Backbone </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
